[toc]

# **爬虫的步骤**

## 1.爬取网页

- 使用 _Urlib_ 封装请求
- 使用 _Beautiful Soup_[文档在这](https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/#id13)
- 通过点取属性的方式只能获得当前名字的第一个 tag
  ```python
  soup.a
  # <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
  ```
- 如果想要得到所有的&lt;a&gt;标签,或是通过名字得到比一个 tag 更多的内容的时候,就需要用到 Searching the tree 中描述的方法,比如: find_all()
  ```python
  soup.find_all('a')
  # [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
  #  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
  #  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
  ```

## 2.解析数据

- 通过 _re_ 库筛选链接  
  **步骤**
  1. 通过 _**re.compile**_ 建立正则表达式
     ```python
     findbd = re.compile(r'<p\sclass="">(.*?)</p>', re.S)
     # 在 _python_ 里面 正则表达式()里面代表匹配的内容
     # 如果（）只有一个 就返回字符串
     # 如果（）多于一个 也就是说要匹配的内容不止一处 则返回tuple
     ```

2. 通过 _**re.findall**_ 查找具体字符串

## 3.保存数据
