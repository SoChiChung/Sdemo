[toc]

# **爬虫的步骤**

## 1.爬取网页

- 使用 _Urlib_ 封装请求
- 使用 _Beautiful Soup_[文档在这](https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/#id13)
- 通过点取属性的方式只能获得当前名字的第一个 tag
  ```python
  soup.a
  # <a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>
  ```
- 如果想要得到所有的&lt;a&gt;标签,或是通过名字得到比一个 tag 更多的内容的时候,就需要用到 Searching the tree 中描述的方法,比如: find_all()
  ```python
  soup.find_all('a')
  # [<a class="sister" href="http://example.com/elsie" id="link1">Elsie</a>,
  #  <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>,
  #  <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>]
  ```

## 2.解析数据

- 通过 _re_ 库筛选链接

## 3.保存数据
